server:
  applicationConnectors:
  - type: http
    port: 0
  adminConnectors:
  - type: http
    port: 0
kafka:
  brokers: ${BROKER_CONNECTION_STRING:-[]}

  adminConfig:
    adminClientRequestTimeoutMs: 2000

  consumers:
    consumer1:
      group: default
      clientId: consumer1
      config:
        key.deserializer: "org.apache.kafka.common.serialization.LongDeserializer"
        value.deserializer: "org.apache.kafka.common.serialization.LongDeserializer"
        metric.reporters: "org.sdase.commons.server.kafka.helper.KafkaMetricsReporter"
        metrics.sample.window.ms: 5000
    consumer2:
      clientId: c2
    consumer3:
      group: consumer3
      clientId: consumer3
      config:
        key.deserializer: "org.apache.kafka.common.serialization.LongDeserializer"
        value.deserializer: "org.apache.kafka.common.serialization.LongDeserializer"

  producers:
    producer1:
      config:
        key.serializer: "org.apache.kafka.common.serialization.LongSerializer"
        value.serializer: "org.apache.kafka.common.serialization.LongSerializer"
        metric.reporters: "org.sdase.commons.server.kafka.helper.KafkaMetricsReporter"
        metrics.sample.window.ms: 5000
    producer2:
      clientId: p2
    producer3:
      config:
        key.serializer: "org.apache.kafka.common.serialization.LongSerializer"
        value.serializer: "org.apache.kafka.common.serialization.LongSerializer"
        metric.reporters: "org.sdase.commons.server.kafka.helper.KafkaMetricsReporter"
        metrics.sample.window.ms: 5000

  listenerConfig:
    async:
      topicMissingRetryMs: 40000
      maxRetries: 3

  topics:
    topicId1:
      name: topic1
    topicId2:
      name: topic2